---
title: "Assignment2-Wang-Oya"
subtitle: "Due at 11:59pm on October 3."
author: "Akari Oya, Zhouer Wang"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#load libraries
library(tidyverse)
library(gtrendsR)
library(censusapi)
```

## Github link = 

In this assignment, you will pull from APIs to get data from various data sources and use your data wrangling skills to use them all together. You should turn in a report in PDF or HTML format that addresses all of the questions in this assignment, and describes the data that you pulled and analyzed. You do not need to include full introduction and conclusion sections like a full report, but you should make sure to answer the questions in paragraph form, and include all relevant tables and graphics.

Whenever possible, use piping and `dplyr`. Avoid hard-coding any numbers within the report as much as possible.

## Pulling from APIs

Our first data source is the Google Trends API. Suppose we are interested in the search trends for `crime` and `loans` in Illinois in the year 2020. We could find this using the following code:

```{r}
res <- gtrends(c("crime", "loans"), 
               geo = "US-IL", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)
plot(res)
```

Answer the following questions for the keywords "crime" and "loans".

-   Find the mean, median and variance of the search hits for the keywords.

```{r}
# Check what the data looks like
res$interest_over_time %>% 
  head()

# Take interest over time data and group data into crime and loans in separate rows
# Also compute the mean, sd, variance of each keyword
res$interest_over_time %>% 
  group_by(keyword) %>% 
  summarize(mean_hits = mean(hits),
            sd_hits = sd(hits),
            var_hits = var(hits))
```
The keyword `crime` had a mean search hit of 55.615 with a standard deviation of 9.282 and a variance of 86.163. The keyword `loans` had a mean search hit of 67.231 with a standard deviation of 9.924 and a variance of 98.495. \

-   Which cities (locations) have the highest search frequency for `loans`? Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city.

```{r}
# Check what the data looks like
res$interest_by_city %>% 
  head()

# Reshape data from long to wide format using keywords
wide_df <- res$interest_by_city %>% 
  pivot_wider(names_from = keyword,
              values_from = hits)

# Check for duplicates in location to see if reshaping worked and show in table if any exist
wide_df %>%
  add_count(location) %>%
  filter(n>1) %>%
  distinct()

# Sort loans column in descending order
wide_df %>%   
  arrange(desc(loans)) %>% 
  head()
```
The cities Long Lake, Erie, and Streamwood have the highest search frequency for `loans`.\

-   Is there a relationship between the search intensities between the two keywords we used?
```{r}
# Run Pearson correlation test
cor.test(wide_df$crime, wide_df$loans)
```
While `loans` had a higher mean search frequency over time, there does not seem to be a large difference between the search frequency of `crime`. However, patterns can be seen in the plot. The two keywords seems to have an inverse relationship where search frequencies for `loans` are high when `crime` is low in the first peak/dip around April 2020. However, the pattern fades after around July 2020. We tested the relationship between the variables for interest by city to properly with a Pearson correlation test. The test suggests that there is no significant correlation (r = -0.115, p = .72). \


Repeat the above for keywords related to covid. Make sure you use multiple keywords like we did above. Try several different combinations and think carefully about words that might make sense within this context.

```{r}
# Create another dataset with new keywords
res2 <- gtrends(c("masks", "deaths"), 
               geo = "US-IL", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)
plot(res2)
```
```{r}
res2 %>% 
  head()

# Compute the mean, standard deviation, and variance of search hits per keyword
res2$interest_over_time %>% 
  group_by(keyword) %>% 
  summarize(mean_hits = mean(hits),
            sd_hits = sd(hits),
            var_hits = var(hits))
```
```{r}
# Check data
res2$interest_by_city %>% 
  head()

# There is a duplicate location name (Willowbrook) and pivot_wider cannot be run. I will remove it from the data for the sake of this assignment
res2_nodup <- res2$interest_by_city %>% 
  filter(!row_number() %in% c(13, 64))

# Reshape data from long to wide format using keywords
wide2_df <- res2_nodup %>% 
pivot_wider(names_from = keyword,
           values_from = hits)

# Sort masks column in descending order
wide2_df %>%   
  arrange(desc(masks)) %>% 
  head()

# Run Pearson correlation test
cor.test(wide2_df$masks, wide2_df$deaths)
```
We used the keywords `masks` and `deaths`. The search frequency for `masks` over time had a mean of 34.250 with a standard deviation of 24.372 and a variance of 593.995. The search frequency for `deaths` over time had a mean of 32.865 with a standard deviation of 22.704 and a variance of 515.491. Both keywords have a similar mean and have high variances. In the plot, the frequencies have a similar shape. The initial spike in search hits of both keywords understandably corresponds to near the beginning of the pandemic when everyone was required to wear masks. We conducted a Pearson correlation test to see if the search frequencies of the two keywords have a relationship. The test revealed that there is no significant correlation (r = 0.04, p = .803).


## Google Trends + ACS

Now lets add another data set. The `censusapi` package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

<https://api.census.gov/data/key_signup.html>

Once you have an access key, store this key in the `cs_key` object. We will use this object in all following API queries.

```{r}
#| eval: false
cs_key <- "your key here"
```

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois.

```{r}
#| eval: false

acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "place:*", 
                    regionin = "state:17",
                    key = cs_key)
head(acs_il)
```

Convert values that represent missings to NAs.

```{r}
#| eval: false

acs_il[acs_il == -666666666] <- NA
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names.

```{r}
#| eval: false
acs_il <-
  acs_il %>%
  rename(pop = B01001_001E, 
         age = B06002_001E, 
         hh_income = B19013_001E, 
         income = B19301_001E)
```

It seems like we could try to use this location information listed above to merge this data set with the Google Trends data. However, we first have to clean `NAME` so that it has the same structure as `location` in the search interest by city data. Add a new variable `location` to the ACS data that only includes city names.

Answer the following questions with the "crime" and "loans" Google trends data and the ACS data.

-   First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

-   Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

-   Is there a relationship between the median household income and the search popularity of the Google trends terms? Describe the relationship and use a scatterplot with `qplot()`.

Repeat the above steps using the covid data and the ACS data.
